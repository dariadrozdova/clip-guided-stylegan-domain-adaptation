# CLIP-направляемая доменная адаптация StyleGAN-2

## Описание работы

В рамках проекта реализован упрощённый вариант метода StyleGAN-NADA (No-Data Domain Adaptation) для адаптации предобученного генератора StyleGAN-2 под новый визуальный домен без использования изображений целевого домена.

В качестве исходной модели используется предобученный генератор StyleGAN-2, обученный на датасете FFHQ (фотографии лиц). Для адаптации создаются две копии генератора:

- **G_frozen** — замороженная копия (служит базовым ориентиром);
- **G_train** — обучаемая копия (адаптируется под новый стиль).

Обучение организовано так, чтобы для одного и того же латентного вектора _z_ изображение, сгенерированное G_train(z), смещалось в сторону целевого домена относительно G_frozen(z).

Направление адаптации задаётся в пространстве CLIP через текстовые описания исходного и целевого доменов. Обучение выполняется без дискриминатора и без использования изображений целевого домена, что соответствует постановке задачи no-data domain adaptation.

Целевой домен в данном проекте: **sketch**.

В репозитории размещён ноутбук без output-ов, так как версия с выводами превышает лимит GitHub на размер файлов.

[Ссылка на Google Colab (ноутбук со всеми outputs)](https://colab.research.google.com/drive/17wWLzXpt65wF_KpLEaHv4n7grA-vrOy8?authuser=1#scrollTo=1MYQ-p_O35r1)

## Исследование важности блоков

Была сформулирована гипотеза о роли блоков генератора в зависимости от уровня:

- **ранние блоки** в основном отвечают за глобальную структуру и пропорции лица;
- **средние блоки** влияют на более детальную структуру и форму отдельных частей (глаза, нос, рот);
- **поздние блоки** в большей степени контролируют локальные детали: контуры, текстуры, цветовые и высокочастотные компоненты.

Так как стиль sketch не предполагает изменения пропорций лица и в первую очередь влияет на линии, контуры и визуальную текстуру, в качестве первого шага была выбрана частичная адаптация: обучение только поздних блоков.

## Эксперимент 1: обучение последних 4 блоков (k = 4)

В первом эксперименте была выполнена разморозка и обучение только последних 4 блоков генератора.

Результат (верхняя строка - G_frozen, нижняя - G_train):

![Эксперимент k=4](results/exp_k4/final_sample_k4.png)

Наблюдение: появляются признаки sketch-стилизации, однако эффект выражен недостаточно, чтобы считать результат полностью удовлетворительным.

## Эксперимент 2: обучение последних 6 блоков (k = 6)

Во втором эксперименте количество обучаемых блоков было увеличено до 6, чтобы усилить влияние на представления среднего уровня и получить более выраженный перенос стиля.

Результат:

![Эксперимент k=6](results/exp_k6/final_sample_k6.png)

Наблюдение: перенос sketch-стиля выражен заметно сильнее, результат визуально более приемлем.

## Вывод по экспериментам

Увеличение числа обучаемых блоков с k = 4 до k = 6 приводит к более выраженному переносу sketch-стиля. На данном этапе результат при k = 6 можно считать приемлемым и использовать как финальный для текущей постановки эксперимента.

## Проверка на новых латентных векторах

Для чистоты эксперимента была проведена генерация новых изображений, не использовавшихся в процессе обучения. Для одних и тех же случайных латентных векторов сравниваются изображения, полученные из замороженной копии генератора (G_frozen) и обучаемой копии (G_train, k = 6).

G_frozen:

![New seed frozen](results/exp_k6/new_seed_frozen.png)

Обученный генератор (G_train, k = 6):

![New seed trained](results/exp_k6/new_seed_trained.png)

Перенос sketch-стиля сохраняется и на новых латентных векторах.


## Обучающий пайплайн

## Общий вывод
