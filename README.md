# CLIP-направляемая доменная адаптация StyleGAN-2

Данный проект основан на идеях, предложенных в работах **StyleCLIP** и **StyleGAN-NADA**, посвящённых CLIP-направляемой адаптации генераторов изображений:

- StyleCLIP: https://github.com/orpatashnik/StyleCLIP  
- StyleGAN-NADA: https://stylegan-nada.github.io/

Целью работы является воспроизведение и практическое исследование этих идей на примере адаптации предобученного генератора StyleGAN-2 под новый визуальный домен без использования изображений целевого домена.

В качестве исходной модели используется предобученный генератор StyleGAN-2, обученный на датасете FFHQ (фотографии лиц). Для адаптации создаются две копии генератора:

- **G_frozen** — замороженная копия (служит базовым ориентиром);
- **G_train** — обучаемая копия (адаптируется под новый стиль).

Обучение организовано так, чтобы для одного и того же латентного вектора _z_ изображение, сгенерированное G_train(z), смещалось в сторону целевого домена относительно G_frozen(z).

Направление адаптации задаётся в пространстве CLIP через текстовые описания исходного и целевого доменов. Обучение выполняется без дискриминатора и без использования изображений целевого домена, что соответствует постановке задачи no-data domain adaptation.

Целевой домен в данном проекте: **sketch**.

-------------

В репозитории размещён ноутбук без output-ов, так как версия с выводами превышает лимит GitHub на размер файлов.

[Ссылка на Google Colab (ноутбук со всеми outputs)](https://colab.research.google.com/drive/17wWLzXpt65wF_KpLEaHv4n7grA-vrOy8?authuser=1#scrollTo=1MYQ-p_O35r1)

Также в репозиторий загружены только итоговые изображения для каждого эксперимента для отчёта. Полная папка с результатами обучения (промежуточные sample-изображения, сравнения, дополнительные визуализации, чекпоинты, логированные лоссы и конфиги) размещена в Google Drive и доступна [по ссылке](https://drive.google.com/drive/folders/1t5SkUlUz4vvXPB7rNqZ1nAUQuTUmdN5e?usp=sharing).

## Исследование важности блоков

Была сформулирована гипотеза о роли блоков генератора в зависимости от уровня:

- **ранние блоки** в основном отвечают за глобальную структуру и пропорции лица;
- **средние блоки** влияют на более детальную структуру и форму отдельных частей (глаза, нос, рот);
- **поздние блоки** в большей степени контролируют локальные детали: контуры, текстуры, цветовые и высокочастотные компоненты.

Так как стиль sketch не предполагает изменения пропорций лица и в первую очередь влияет на линии, контуры и визуальную текстуру, в качестве первого шага была выбрана частичная адаптация: обучение только поздних блоков.

## Эксперимент 1: обучение последних 4 блоков (k = 4)

В первом эксперименте была выполнена разморозка и обучение только последних 4 блоков генератора.

Результат (верхняя строка - G_frozen, нижняя - G_train):

![Эксперимент k=4](results/exp_k4/final_sample_k4.png)

Наблюдение: появляются признаки sketch-стилизации, однако эффект выражен недостаточно, чтобы считать результат полностью удовлетворительным.

## Эксперимент 2: обучение последних 6 блоков (k = 6)

Во втором эксперименте количество обучаемых блоков было увеличено до 6, чтобы усилить влияние на представления среднего уровня и получить более выраженный перенос стиля.

Результат:

![Эксперимент k=6](results/exp_k6/final_sample_k6.png)

Наблюдение: перенос sketch-стиля выражен заметно сильнее, результат визуально более приемлем.

## Вывод по экспериментам

Увеличение числа обучаемых блоков с k = 4 до k = 6 приводит к более выраженному переносу sketch-стиля. На данном этапе результат при k = 6 можно считать приемлемым и использовать как финальный для текущей постановки эксперимента.

## Проверка на новых латентных векторах

Для чистоты эксперимента была проведена генерация новых изображений, не использовавшихся в процессе обучения. Для одних и тех же случайных латентных векторов сравниваются изображения, полученные из замороженной копии генератора (G_frozen) и обучаемой копии (G_train, k = 6).

G_frozen:

![New seed frozen](results/exp_k6/new_seed_frozen.png)

Обученный генератор (G_train, k = 6):

![New seed trained](results/exp_k6/new_seed_trained.png)

Перенос sketch-стиля сохраняется и на новых латентных векторах.


<details>
<summary><b>Описание обучающего пайплайна</b></summary>

#### Организация эксперимента

Для каждого запуска создаётся отдельная директория в Google Drive, в которой сохраняются промежуточные изображения, чекпоинты и численные логи. Это позволяет продолжать обучение после прерываний Colab и анализировать динамику эксперимента.

#### Инициализация моделей

В качестве исходной модели используется предобученный генератор StyleGAN-2 (FFHQ). Создаются две его копии - полностью замороженная `G_frozen` и обучаемая копия `G_train`. `G_frozen` служит референсом для оценки изменений, а `G_train` оптимизируется в направлении целевого домена.

#### Частичная разморозка блоков

Для исследования важности блоков StyleGAN-2 обучение проводится только на части слоёв. Все параметры `G_train` изначально замораживаются, после чего размораживаются только последние `k` блоков синтеза (эксперименты с `k = 4` и `k = 6`).

#### CLIP-направление адаптации

Для направления доменной адаптации используется модель CLIP. Направление в CLIP-пространстве определяется разностью эмбеддингов текстовых описаний исходного и целевого доменов (из photo в sketch).

Изображения, сгенерированные `G_frozen` и `G_train` для одного и того же латентного вектора, сравниваются в пространстве CLIP, что позволяет оптимизировать только направление изменения изображения без использования изображений целевого домена.

#### Функция потерь

Используется directional CLIP loss, который максимизирует косинусное сходство между направлением изменения изображения (`G_train(z) − G_frozen(z)` в CLIP-пространстве) и направлением между текстовыми описаниями доменов.

#### Параметры обучения

Обучение проводится с использованием оптимизатора Adam при `batch_size = 1` и фиксированном числе шагов. Эти параметры выбраны с учётом ограничений бесплатного GPU Colab и необходимости получить воспроизводимый результат за разумное время.

#### Контроль обучения

Для мониторинга прогресса используются фиксированные латентные векторы. Периодически сохраняются изображения, в которых в одной сетке сравниваются результаты `G_frozen` и `G_train`. Это позволяет визуально отслеживать процесс доменной адаптации и сравнивать эксперименты между собой.

#### Логирование

Во время обучения сохраняются значения лосса и чекпоинты, что позволяет продолжать обучение после прерывания и анализировать поведение модели на разных этапах.
</details>

## Общий вывод